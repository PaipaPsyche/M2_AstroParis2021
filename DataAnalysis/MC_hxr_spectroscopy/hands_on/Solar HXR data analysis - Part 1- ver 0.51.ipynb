{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to import external libraries. These libraries will enable us to do complicated data analysis.\n",
    "You will need to install these libraries inside your python environment beforehand for this to work. Refer to the helper document that we have sent you for more details.\n",
    "\n",
    "We will be using numpy for storing and manipulating data as arrays, matplotlib for plotting functions, datetime for working with time data, astropy for FITS I/O operations and sunpy for solar specific instrument I/O operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from astropy.io import fits\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as plt_dates\n",
    "import matplotlib.ticker as mticker\n",
    "from sunpy.time import TimeRange, parse_time\n",
    "from astropy.time import Time, TimeDelta\n",
    "import astropy.units as u\n",
    "from datetime import datetime\n",
    "from scipy import stats\n",
    "from functools import partial\n",
    "from datetime import timedelta "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Func1\n",
    "def moving_average(arr, w):\n",
    "    '''\n",
    "    Compute a moving average.\n",
    "    \n",
    "    Parameters:\n",
    "    ------------\n",
    "    arr : 'array'\n",
    "         One-dimensional array on which the moving average needs to be computed\n",
    "    w : 'int'\n",
    "         Window-size of the moving average. Should be less than the size of the array.\n",
    "         \n",
    "    Returns:\n",
    "    ----------\n",
    "    out: 'array'\n",
    "         The computed array\n",
    "    \n",
    "    '''\n",
    "    return np.convolve(arr, np.ones(w), 'valid') / w\n",
    "\n",
    "\n",
    "#Func2\n",
    "def integrate_over_time(arr,integration_time,avg=False):\n",
    "    '''\n",
    "    Integrate over time by summing over in chunks of data\n",
    "    \n",
    "    Parameters:\n",
    "    -------------\n",
    "    arr: 'array'\n",
    "         One-dimensional array on which the integration needs to be computed\n",
    "    integration_time: 'int'\n",
    "         Should be multiples of 4.\n",
    "         The data would be divided in chunks depending on the number of data points\n",
    "         and the integration time requested.\n",
    "         \n",
    "    Returns:\n",
    "    ------------\n",
    "    arr_int: 'array'\n",
    "         \n",
    "    '''\n",
    "    chunk_no = len(arr)//(integration_time/4)\n",
    "    if avg:\n",
    "        arr_int = np.array([sum(arr)/len(arr) for arr in np.array_split(arr,chunk_no)])\n",
    "    else:\n",
    "        arr_int = np.array([sum(arr) for arr in np.array_split(arr,chunk_no)])\n",
    "    return arr_int\n",
    "\n",
    "#Func3\n",
    "def convert_seconds_datetime(sod_i,date_obs):\n",
    "    '''\n",
    "    Convert seconds of day into a datetime object\n",
    "    \n",
    "    Parameters:\n",
    "    ------------\n",
    "    sod_i:'float'\n",
    "          A single element of seconds of day. Should be between 0 and 86400.0\n",
    "    date_obs:'str'\n",
    "          The date of the observation in YYYY-MM-DD format\n",
    "    Returns:\n",
    "    -----------\n",
    "    out: 'datetime'\n",
    "    '''\n",
    "    for fmt in ('%Y-%m-%dT%H:%M:%S.%f', '%Y-%m-%dT%H:%M:%S'):\n",
    "        try:\n",
    "            return datetime.strptime(date_obs+'T'+str(timedelta(seconds=sod_i)), fmt)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RHESSI Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Reuven Ramaty High Energy Solar Spectroscopic Imager (RHESSI) was a NASA Small Explorer Mission, launched on February 5, 2002. The primary mission of RHESSI was to explore how particle energization happened during the explosive energy release associated with a solar flare. This was achieved through state-of-the art imaging spectroscopy in X-rays and gamma-rays with fine angular and energy resolution. This enabled the study of flare locations and the spectra of accelerated electrons and ions of the hottest plasma.\n",
    "\n",
    "After 16 years of successful operation, RHESSI was finally decommissioned on August 16,2018. During its lifetime, RHESSI observed more than 120000 X-ray events, providing us with a wealth of data to understand and analyse. \n",
    "\n",
    "In this section, you will start with the basic I/O operations from the RHESSI.\n",
    "                                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are interested in RHESSI Quicklook information. The Observing Summary is obtained directly from the telemetry packets. The photons are time-binned and the count rate is compressed to bytes (0.03 accuracy up to 1.0e6 counts/sec). Aspect solution, pointing, roll angle and roll period are given also. The nominal interval time for the count rates is the spin period of the spacecraft, 4 seconds, ephemeris info is given every 20 seconds , aspect info is given every second, roll period is given every 20 seconds.\n",
    "\n",
    "As you can see, the quicklook file contains plenty of information which are all not needed for plotting a lightcurve. Hence we have created an easy to operate file for you. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-25T07:09:50.552522Z",
     "start_time": "2021-10-25T07:09:50.543837Z"
    }
   },
   "outputs": [],
   "source": [
    "#task 1\n",
    "def parse_rhessi_fits(fits_filename):\n",
    "    '''\n",
    "    This function will allow you to open a RHESSI fits file,\n",
    "    read and retrieve data, and then store it inside a dictionary.\n",
    "    \n",
    "    You've to pass this dictionary and the primary HEADER back for \n",
    "    further processing.\n",
    "    The structure of fits file is as follows\n",
    "    0 - Counts\n",
    "    1 - Flags\n",
    "    '''\n",
    "    \n",
    "    hdul = fits.open(fits_filename)\n",
    "    header =                                  #complete this code(1 line)\n",
    "    \n",
    "    Counts =                               #complete this code(1 line)\n",
    "    Flags =                                #complete this code(1 line)\n",
    "    \n",
    "    labels = ['3 - 6 keV', '6 - 12 keV', '12 - 25 keV', '25 - 50 keV',\n",
    "              '50 - 100 keV', '100 - 300 keV', '300 - 800 keV',\n",
    "              '800 - 7000 keV', '7000 - 20000 keV']\n",
    "    \n",
    "    data = {'data': Counts, 'labels': labels,'flags':Flags}\n",
    "    \n",
    "    return header,data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhessi_header,rhessi_data = parse_rhessi_fits()         #call the function by passing the filename\n",
    "print(rhessi_header)\n",
    "print(rhessi_data['data'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you may have noticed the time information is not passed down. Thus we need to create an array to plot the data\n",
    "accurately. We will create a time array from the information we obtained from the header. \n",
    "We need two quantities here, the date of the observation 'DATE_OBS' and the size of the time axis 'NAXIS2'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-25T07:19:10.482493Z",
     "start_time": "2021-10-25T07:19:10.425823Z"
    }
   },
   "outputs": [],
   "source": [
    "# you need to fill in the appropriate quantities from the header\n",
    "# to get a time array. Please note you need to remove the strings.\n",
    "# They are there only as a guide.\n",
    "# The time array we are creating are for the whole duration of the observation time\n",
    "# mentioned in the HEADER. Later we will slice this file to collect data\n",
    "# for the flare we are interested in\n",
    "\n",
    "time_array = parse_time(' Enter DATE_OBS here') + \\\n",
    "        TimeDelta(4.0 * np.arange('Enter NAXIS2 here') * u.second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that you've the time array, add that to the 'rhessi_data' dictionary\n",
    "# under the key name 'time'\n",
    "                                                           #complete this code(1 line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute this line to convert the timearray we created into datetime format\n",
    "hxr_time = rhessi_data['time'].datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are defining the flare time here \n",
    "# you don't need to implement anything here\n",
    "date_ = [1,6,2013]\n",
    "timerange_st = [13,30,0]\n",
    "timerange_end = [13,50,0]\n",
    "\n",
    "time_param = {}\n",
    "time_param['date start'] = date_\n",
    "time_param['date end'] = date_\n",
    "time_param['time start'] = timerange_st\n",
    "time_param['time end'] = timerange_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the time parameters into individual variables \n",
    "# for day, hour,min and seconds for accurate slicing of the time axis.\n",
    "# For examples here start date and end date are the same. However\n",
    "# we pass two seperate variables for generalisation purposes\n",
    "\n",
    "dd_st,mm_st,yyyy_st =                          #complete this code\n",
    "hh_st,MM_st,ss_st =                             #complete this code\n",
    "dd_en,mm_en,yyyy_en =                           #complete this code\n",
    "hh_en,MM_en,ss_en =                             #complete this code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now you need to slice the time axis. We do this by checking\n",
    "# the array indices of the time points within the defined time above.\n",
    "# We will pass these indices for collecting data only within the \n",
    "# defined time interval.\n",
    "\n",
    "# you need to pass a datetime object in the place of the two strings added here\n",
    "# the datetime object is in the form:\n",
    "# datetime(yyyy, mm, dd,hh,MM,ss)\n",
    "\n",
    "hxr_idx = np.where((hxr_time >= 'Start time (Remove this string)' ) &        #enter your code after removing the string\n",
    "                          (hxr_time <= 'End time (Remove this string)'))[0]  #enter your code after removing the string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will now plot and see the flare that we are interested in\n",
    "# You need to complete the code by passing an axis object \n",
    "# and the data along with hxr_idx that we calculated above.\n",
    "# We will be using plot_date instead of plot, because the x-axis is time\n",
    "# The code that you need to write should be in the following format.\n",
    "# axis_obj.plot_date(hxr_dates[idx],rhessi_data['data'][idx,chan 1].ravel(),'-')\n",
    "\n",
    "fig = plt.figure(figsize=(9,3),facecolor='w')\n",
    "axes = fig.subplots(nrows=1,ncols=1,)                      #axis object\n",
    "hxr_dates = plt_dates.date2num(hxr_time)\n",
    "\n",
    "l1, =                                       #your code here  (chan 1)\n",
    "l2, =                                       #your code here  (chan 2)\n",
    "l3, =                                       #your code here  (chan 3)\n",
    "l4, =                                       #your code here  (chan 4)\n",
    "axes.legend((l1,l2,l3,l4), ('3-6 keV', '6-12 keV','12-25 keV','25-50 keV'),\n",
    "                             loc='upper right')\n",
    "l5 = axes.plot_date(hxr_dates[atten1],np.ones_like(hxr_dates[atten1])*hxrCounts[hxr_idx,:].max()*1.05,'r')\n",
    "axes.minorticks_on()\n",
    "axes.yaxis.set_minor_locator(mticker.MultipleLocator(5))\n",
    "axes.set_yscale(\"log\")\n",
    "axes.set_ylabel('counts/s')\n",
    "axes.yaxis.grid(True, 'major')\n",
    "date_format = plt_dates.DateFormatter('%H:%M')\n",
    "axes.xaxis.set_major_formatter(date_format)\n",
    "axes.text(0.5, -0.2, datetime.date(hxr_time[0]).strftime(\"%d/%m/%Y\"), ha='center', va='center',\n",
    "         transform=axes.transAxes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will now integrate the data over time and see how the data changes \n",
    "# as a function of the time interval chosen.\n",
    "# The function that will help you to integrate is already given to you \n",
    "# in the helper section.\n",
    "\n",
    "int_time =                                 # choose a multiple of 4\n",
    "\n",
    "#We are integrating the time axis here. Pass in the quantities\n",
    "hxr_dates_int = integrate_over_time(' ' ,' '  ,avg=True)       \n",
    "\n",
    "# Now we will integrate the counts.\n",
    "# To make the process efficient we are using a special function called apply_along_axis\n",
    "# You can pass in the whole count array within the time we are interested in.\n",
    "\n",
    "hxr_counts_int = np.apply_along_axis(integrate_over_time, 0, \n",
    "                                      'whole count array within hxr idx ',integration_time='integration time  ')\n",
    "fig = plt.figure(figsize=(9,3),facecolor='w')\n",
    "axes = fig.subplots(nrows=1,ncols=1,)\n",
    "hxr_dates = plt_dates.date2num(hxr_time)\n",
    "\n",
    "#complete the followin code to plot it\n",
    "# Similar to the first plot, you need to pass the \n",
    "# axes object and the data for x and y axis.\n",
    "l1,= \n",
    "l2,= \n",
    "l3,= \n",
    "l4,=\n",
    "axes.legend((l1,l2,l3,l4), ('3-6 keV', '6-12 keV','12-25 keV','25-50 keV'),\n",
    "                             loc='upper right')\n",
    "l5 = axes.plot_date(hxr_dates[atten1],np.ones_like(hxr_dates[atten1])*hxrCounts[hxr_idx,:].max()*1.05,'r')\n",
    "axes.minorticks_on()\n",
    "axes.yaxis.set_minor_locator(mticker.MultipleLocator(5))\n",
    "axes.set_yscale(\"log\")\n",
    "axes.set_ylabel('counts/s')\n",
    "axes.yaxis.grid(True, 'major')\n",
    "date_format = plt_dates.DateFormatter('%H:%M')\n",
    "axes.xaxis.set_major_formatter(date_format)\n",
    "axes.text(0.5, -0.2, datetime.date(hxr_time[0]).strftime(\"%d/%m/%Y\"), ha='center', va='center',\n",
    "         transform=axes.transAxes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify this function to get the Poisson statistics\n",
    "def Poissonsignaltonoise(signal,axis=0):\n",
    "    noise=                       # complete the code to get noise. You will have to use numpy sqrt function\n",
    "    signaltonoise=signal/noise\n",
    "    return signaltonoise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now experiment with different integration times and how this is affecting \n",
    "#Poisson statistics\n",
    "int_time =                                 # choose a multiple of 4\n",
    "\n",
    "#We are integrating the time axis here. Pass in the quantities \n",
    "hxr_dates_int = integrate_over_time(   ,   ,avg=True)       \n",
    "\n",
    "# Now we will integrate the counts.\n",
    "# To make the process efficient we are using a special function called apply_along_axis\n",
    "# You can pass in the whole count array within the time we are interested in.\n",
    "\n",
    "hxr_counts_int = np.apply_along_axis(integrate_over_time, 0, \n",
    "                                      'whole count array within hxr idx ',integration_time='integration time  ')\n",
    "\n",
    "fig = plt.figure(figsize=(9,3),facecolor='w')\n",
    "axes = fig.subplots(nrows=1,ncols=1,)\n",
    "hxr_dates = plt_dates.date2num(hxr_time)\n",
    "#fill in the rest of the code to plot poisson statistics of the light curve\n",
    "# you can copy the code from the previous plots\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STIX Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STIX is the modern day replacement of RHESSI. STIX is one of the instrument onboard Solar Orbiter which was launched on February 10,2020. Solar Orbiter will get as close as 60 solar radii from the Sun. This will give unprecedented opportunities to observe the Sun in multiple wavelengths up close. The design philosophy of STIX is very similar to that of RHESSI, however the implementation is very different owing to advancements in technology and the need to have extremely low rates of telemetry. \n",
    "\n",
    "In this exercise, you will open a STIX quick look fits file to plot the light curves similar to RHESSI. However, we will be using the original data file obtained from STIX without any modification. For RHESSI, we avoided using the original file for ease of use. STIX file on the contrary is already condensed and contains much less information to unpack compared to RHESSI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We highly recommend you to run the following code to get an understanding \n",
    "#of the structure of STIX data file given to you.\n",
    "# The data is stored in a TABLE format at position 3 (hdulist[2])\n",
    "# We need the 'time' and 'counts' column from this table,\n",
    "# which you will implement in the function below\n",
    "\n",
    "hdulist = fits.open('STIX file name')\n",
    "hdulist[2].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_stix_ql(fits_filename):\n",
    "    '''\n",
    "    Implement this function to read a STIX fits file\n",
    "    You need to return from this function the header and the data in a dictionary format\n",
    "    \n",
    "    To read the time and counts you need to remember the position at which they are stored.\n",
    "    To read a column from a table in a FITS file you need to use the command \n",
    "    hdulist[table_position].data.field('column_name')\n",
    "    You need to find the table_position and 'column_name'\n",
    "    Please note table_position is int and 'column_name' is str\n",
    "    '''\n",
    "    hdulist = fits.open(fits_filename)\n",
    "    header =                                 #your code here(1 line)\n",
    "    time_sod =                               #your code here(1 line)(put the 'time' field here)\n",
    "    counts =                                 #your code here(1 line)(put the 'counts' field here)\n",
    "    labels = [str(x)+'-'+str(y)+' keV' for x,y in zip(hdulist[3].data['e_low'],hdulist[3].data['e_high'])]\n",
    "    \n",
    "    data = {'time':time_sod,'data':counts,'labels':labels}\n",
    "    return header,data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stix_header,stix_data = parse_stix_ql()         #call the function by passing the filename\n",
    "\n",
    "print(stix_header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unlike RHESSI we get the time information from the fits file itself\n",
    "# for STIX. However it is in seconds of day format. \n",
    "# We will now convert it into datetime format similar to RHESSI\n",
    "# For date_obs_str you need to pass the 'DATE_AVG' entry from the header file.\n",
    "\n",
    "date_obs_str = \n",
    "map_func = partial(convert_seconds_datetime,\n",
    "                    date_obs=date_obs_str.split('T')[0])\n",
    "time_arr = np.asarray(list(map(map_func,'Enter time array from STIX ')))   #pass in time array from stix_data\n",
    "                                                                           #You've to complete the code by replacing\n",
    "                                                                           #the string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that you've the time array, replace the time in 'stix_data' dictionary\n",
    "# under the key name 'time'\n",
    "                                                           #complete this code(1 line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are defining the time here\n",
    "# You don't need to add anything here\n",
    "date_ = [7,5,2021]\n",
    "timerange_st = [18,40,0]\n",
    "timerange_end = [19,30,0]\n",
    "\n",
    "time_param = {}\n",
    "time_param['date start'] = date_\n",
    "time_param['date end'] = date_\n",
    "time_param['time start'] = timerange_st\n",
    "time_param['time end'] = timerange_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First assign the date time variables similar to what you have done for RHESSI\n",
    "\n",
    "# As before you need to slice the time axis. We do this by checking\n",
    "# the array indices of the time points within the defined time above.\n",
    "# We will pass these indices for collecting data only within the \n",
    "# defined time interval.\n",
    "\n",
    "# you need to pass a datetime object in the place of the two strings added here\n",
    "# the datetime object is in the form:\n",
    "# datetime(yyyy, mm, dd,hh,MM,ss)\n",
    "\n",
    "dd_st,mm_st,yyyy_st =   #your code here \n",
    "hh_st,MM_st,ss_st =     #your code here \n",
    "dd_en,mm_en,yyyy_en =   #your code here \n",
    "hh_en,MM_en,ss_en =     #your code here \n",
    "hxr_idx = np.where((stix_data['time'] >= 'your code ') &                          # pass in the datetime objects\n",
    "                          (stix_data['time'] <= 'your code '))[0]                 # refer to what you've done in the case\n",
    "                                                                         # of RHESSI. Enter your code by replacing the \n",
    "                                                                         # strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now plot the data. Follow the same format as you did for RHESSI\n",
    "fig = plt.figure(figsize=(9,3),facecolor='w')\n",
    "axes = fig.subplots(nrows=1,ncols=1,)\n",
    "hxr_dates = plt_dates.date2num(stix_data['time'])\n",
    "l1, =                                                     #your code here\n",
    "l2, =                                                     #your code here\n",
    "l3, =                                                     #your code here\n",
    "l4, =                                                     #your code here\n",
    "axes.legend((l1,l2,l3,l4), ('4-10 keV', '10-15 keV','15-25 keV','25-50 keV'),\n",
    "                             loc='upper right')\n",
    "l5 = axes.plot_date(hxr_dates[atten1],np.ones_like(hxr_dates[atten1])*hxrCounts[hxr_idx,:].max()*1.05,'r')\n",
    "axes.minorticks_on()\n",
    "axes.yaxis.set_minor_locator(mticker.MultipleLocator(5))\n",
    "axes.set_yscale(\"log\")\n",
    "axes.set_ylabel('counts')\n",
    "axes.yaxis.grid(True, 'major')\n",
    "date_format = plt_dates.DateFormatter('%H:%M')\n",
    "axes.xaxis.set_major_formatter(date_format)\n",
    "axes.text(0.5, -0.2, datetime.date(stix_data['time'][0]).strftime(\"%d/%m/%Y\"), ha='center', va='center',\n",
    "         transform=axes.transAxes)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 122.844,
   "position": {
    "height": "40px",
    "left": "1492px",
    "right": "20px",
    "top": "8px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
